{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dzNng6vCL9eP"
   },
   "source": [
    "## CSC4815 Machine Learning\n",
    "Homework 4 due on 4/22 at midnight\n",
    "\n",
    "__Noah Foilb__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "Rules:\n",
    "- All the problems must be solved programmatically. No manual solution will be accepted. Do not hard-code constants unless they are given as parts of a problem.\n",
    "- Solve each problem only in the given cell and show the final result. Do not leave debugging information.  __Do not add cells__.\n",
    "- You may not import any external modules other than numpy, pandas, sklearn, and matplotlib. Take advantage of the code examples accompanying each sklearn API on their website.\n",
    "- Always try to make the output informative and intuitive. That's what your client will care about in the end. Add description/label to the output values.\n",
    "- <font color='red'>A solution ending with a syntax or runtime error will get zero points no matter how much you worked on it. It will be much better to submit an error-free, partial solution than a solution which never runs.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to ensure you are using Python 3 or above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1L4Am0QATgOc",
    "outputId": "bb5ee3ac-8683-44ab-e599-a2077510f327",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.3\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "[9 points] Your task is to perform classification on the attched dataset using Decision Tree, Random Forest, and AdaBoost algorithms. This task involves the end-to-end machine learning workflow. Follow the following information and guidelines:\n",
    "\n",
    "- The attribute names of the dataset: age, workclass, fnlwgt, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, captial-loss , hours-per-week, native-country, and income in the give order. income is the class label.\n",
    "- In throry, Decision Trees should be able to handle categorical attributes. However, the Sklearn implementation accepts numerical attributes only.\n",
    "- When the dataset is preprocessed, use the 70% hold-out method with random_state=42 before the first training begins.\n",
    "- Train each algorithm using the same train set (X_train, y_train). Use the default configuration for the algorithms except setting the random_state to 42.\n",
    "- Evaluate the performance of each trained classifier in terms of precision, recall and f-1 on the test set. Additionally, for each trained classifier, compare its accuracy performance on the training set (X_train, y_train), test set (X_test, y_test) and entire set (X, y), \n",
    "- The minimum requirement for partial points is an accuracy better than 80% from each algorithm on each of the training, test and entire set. Additional requirements are given below.\n",
    "- Each output from your code must be annotated informatively and meaningfully. (In other words, do not display numbers without a proper context.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports go in this cell only.\n",
    "# You may import numpy, pandas and sklearn modules only.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_precision_recall_curve \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Schema of the data is: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>captial-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "1   38            Private  215646     HS-grad              9   \n",
       "2   53            Private  234721        11th              7   \n",
       "3   28            Private  338409   Bachelors             13   \n",
       "4   37            Private  284582     Masters             14   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "1             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "2   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "3   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "4   Married-civ-spouse     Exec-managerial            Wife   White   Female   \n",
       "\n",
       "   capital-gain  captial-loss  hours-per-week  native-country  income  \n",
       "0             0             0              13   United-States   <=50K  \n",
       "1             0             0              40   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40            Cuba   <=50K  \n",
       "4             0             0              40   United-States   <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"data\",delimiter=',')         # Read_csv to get data into python and delimiter to create dataframe\n",
    "                                         \n",
    "df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',    # Rename Columns\n",
    "              'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'captial-loss',\n",
    "              'hours-per-week', 'native-country','income']\n",
    "\n",
    "print(\"The Schema of the data is:\",\"\\n\")\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape (32560, 75), y Shape (32560,)\n",
      "X_train Shape (22792, 75), y_train Shape (22792,)\n",
      "X_test Shape (9768, 75), y_test Shape (9768,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "#df.isna().sum()               #There is no na values!\n",
    "#df['income'].unique()         # Income consists of <=50k and >50k\n",
    "\n",
    "# Chance categorical variables to binary, onehotcoding\n",
    "\n",
    "# Workclass\n",
    "Df = pd.get_dummies(df['workclass'], prefix='workclass')        # Create the one hot encoding\n",
    "df = pd.concat([df,Df],axis = 1)                                # Was thinking about getting rid of ? but I think that is not the same as NA\n",
    "\n",
    "# Native-Country\n",
    "Df = pd.get_dummies(df['native-country'], prefix='native-country')        # Create the one hot encoding\n",
    "df = pd.concat([df,Df],axis = 1)  \n",
    "\n",
    "# Martial Status\n",
    "Df = pd.get_dummies(df['marital-status'], prefix='marital-status')        # Create the one hot encoding\n",
    "df = pd.concat([df,Df],axis = 1)  \n",
    "\n",
    "# Relationship\n",
    "Df = pd.get_dummies(df['relationship'], prefix='relationship')        # Create the one hot encoding\n",
    "df = pd.concat([df,Df],axis = 1)  \n",
    "\n",
    "# Martial Status\n",
    "Df = pd.get_dummies(df['race'], prefix='race')        # Create the one hot encoding\n",
    "df = pd.concat([df,Df],axis = 1)  \n",
    "\n",
    "# Income\n",
    "df['income'] = df['income'].str.replace('<=50K','0')    # Replace <=50k with 0, and >50K with 1  \n",
    "df['income'] = df['income'].str.replace('>50K','1')     # had to have help to find out to use .str\n",
    "df['income'] = df['income'].astype('int')\n",
    "\n",
    "# Sex\n",
    "df['sex'] = df['sex'].str.replace('Male','0')\n",
    "df['sex'] = df['sex'].str.replace('Female','1')\n",
    "df['sex'] = df['sex'].astype('int')\n",
    "\n",
    "# Drop columns\n",
    "df = df.drop(columns = ['fnlwgt','education','occupation','workclass','native-country','marital-status','relationship','race']) # get rid of useless columns\n",
    "\n",
    "# Prepare train and test sets:\n",
    "X = df.drop(columns = 'income')                  # Original X, y\n",
    "y = df['income']        \n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state = 42)    # Test/train datasets\n",
    "\n",
    "\n",
    "# Uncomment to show the shapes of the entire, training and test sets.\n",
    "# Do not modify variable names.\n",
    "\n",
    "print(f'X Shape {X.shape}, y Shape {y.shape}')\n",
    "print(f'X_train Shape {X_train.shape}, y_train Shape {y_train.shape}')\n",
    "print(f'X_test Shape {X_test.shape}, y_test Shape {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each Model I will show the Confusion Matrix, Accuracy, Precision, Recall, and f-1 score. Then show the \n",
      "accuracy of the model against the test, train and entire dataset \n",
      "\n",
      " \t Decision Tree \n",
      " Confusion Matrix: \n",
      " [[6590  805]\n",
      " [ 954 1419]] \n",
      " Precision: 0.63804 \n",
      " Recall: 0.59798 \n",
      " F-1 Score: 0.61736 \n",
      " Accuracy \n",
      " \tTest dataset: 0.81992 \n",
      " \tTrain dataset: 0.95691 \n",
      " \tEntire dataset: 0.91582 \n",
      "\n",
      "\n",
      " \t Random Forest \n",
      " Confusion Matrix: \n",
      " [[6796  599]\n",
      " [ 917 1456]] \n",
      " Precision: 0.70852 \n",
      " Recall: 0.61357 \n",
      " F-1 Score: 0.65763 \n",
      " Accuracy \n",
      " \tTest dataset: 0.8448 \n",
      " \tTrain dataset: 0.95691 \n",
      " \tEntire dataset: 0.92328 \n",
      "\n",
      "\n",
      " \t AdaBoost \n",
      " Confusion Matrix: \n",
      " [[6971  424]\n",
      " [ 977 1396]] \n",
      " Precision: 0.76703 \n",
      " Recall: 0.58828 \n",
      " F-1 Score: 0.66587 \n",
      " Accuracy \n",
      " \tTest dataset: 0.85657 \n",
      " \tTrain dataset: 0.85899 \n",
      " \tEntire dataset: 0.85826 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Decision Tree, Random Forest, and AdaBoost here.\n",
    "# Algorithms must be trained on the train set only.\n",
    "# No data processing or preparation may take place in this step.\n",
    "# Generate a confusion matrix, precision, recall and f-1 score\n",
    "# from each trained classifier on the test set.\n",
    "# In addition, compare the accuracy of each trained algorithm\n",
    "# on each of the train, test and entire sets.\n",
    "# Label each output clearly and informatively.\n",
    "\n",
    "# CLASSIFIER\n",
    "# 1 Train model\n",
    "# 2 Confusion matrix, precision, recall and f-1 score on test set\n",
    "# 3 Now compute accuracy on the train, test and entire dataset. All have to be >80%\n",
    "\n",
    "\n",
    "\n",
    "# DECISION TREE\n",
    "# 1 Train model\n",
    "Dec_Tree = DecisionTreeClassifier(random_state=42)\n",
    "Dec_Tree.fit(X_train,y_train)\n",
    "\n",
    "# 2 Confusion matrix, precision, recall and f-1 score on test set\n",
    "y_pred = Dec_Tree.predict(X_test)\n",
    "Dec_c = confusion_matrix(y_test,y_pred)\n",
    "Dec_p = precision_score(y_test,y_pred)\n",
    "Dec_r = recall_score(y_test,y_pred)\n",
    "Dec_f = f1_score(y_test,y_pred)\n",
    "\n",
    "# 3 Now compute accuracy on the train, test and full dataset. All have to be >80%\n",
    "# Test set\n",
    "y_pred = Dec_Tree.predict(X_test)\n",
    "Dec_te = accuracy_score(y_test,y_pred)\n",
    "\n",
    "# Train set\n",
    "y_pred = Dec_Tree.predict(X_train)\n",
    "Dec_tr = accuracy_score(y_train,y_pred)\n",
    "\n",
    "# Entire set\n",
    "y_pred = Dec_Tree.predict(X)\n",
    "Dec_y = accuracy_score(y,y_pred)\n",
    "\n",
    "\n",
    "\n",
    "# RANDOM FOREST\n",
    "# 1 Train model\n",
    "Ran_For = RandomForestClassifier(random_state=42)\n",
    "Ran_For.fit(X_train,y_train)\n",
    "\n",
    "# 2 Confusion matrix, precision, recall and f-1 score on test set\n",
    "y_pred = Ran_For.predict(X_test)\n",
    "Ran_c = confusion_matrix(y_test,y_pred)\n",
    "Ran_p = precision_score(y_test,y_pred)\n",
    "Ran_r = recall_score(y_test,y_pred)\n",
    "Ran_f = f1_score(y_test,y_pred)\n",
    "\n",
    "# 3 Now compute accuracy on the train, test and full dataset. All have to be >80%\n",
    "# Test set\n",
    "y_pred = Ran_For.predict(X_test)\n",
    "Ran_te = accuracy_score(y_test,y_pred)\n",
    "\n",
    "# Train set\n",
    "y_pred = Ran_For.predict(X_train)\n",
    "Ran_tr = accuracy_score(y_train,y_pred)\n",
    "\n",
    "# Entire set\n",
    "y_pred = Ran_For.predict(X)\n",
    "Ran_y = accuracy_score(y,y_pred)\n",
    "\n",
    "\n",
    "\n",
    "# ADABOOST\n",
    "# 1 Train model\n",
    "Ada_Boo = AdaBoostClassifier(random_state=42)\n",
    "Ada_Boo.fit(X_train,y_train)\n",
    "\n",
    "# 2 Confusion matrix, precision, recall and f-1 score on test set\n",
    "y_pred = Ada_Boo.predict(X_test)\n",
    "Ada_c = confusion_matrix(y_test,y_pred)\n",
    "Ada_p = precision_score(y_test,y_pred)\n",
    "Ada_r = recall_score(y_test,y_pred)\n",
    "Ada_f = f1_score(y_test,y_pred)\n",
    "\n",
    "# 3 Now compute accuracy on the train, test and full dataset. All have to be >80%\n",
    "# Test set\n",
    "y_pred = Ada_Boo.predict(X_test)\n",
    "Ada_te = accuracy_score(y_test,y_pred)\n",
    "\n",
    "# Train set\n",
    "y_pred = Ada_Boo.predict(X_train)\n",
    "Ada_tr = accuracy_score(y_train,y_pred)\n",
    "\n",
    "# Entire set\n",
    "y_pred = Ada_Boo.predict(X)\n",
    "Ada_y = accuracy_score(y,y_pred)\n",
    "\n",
    "\n",
    "\n",
    "# Display results\n",
    "# Show confusion matrix, precision, recall, and f-1 score. Then compare the models accuracy against the test, train and entrie dataset.\n",
    "# Show up to 5 decimal digits\n",
    "print(\"For each Model I will show the Confusion Matrix, Accuracy, Precision, Recall, and f-1 score. Then show the\", \"\\n\"+\n",
    "      \"accuracy of the model against the test, train and entire dataset\",\"\\n\"*2,\n",
    "     \"\\t\",\"Decision Tree\",\"\\n\",\n",
    "     \"Confusion Matrix:\",\"\\n\",Dec_c,\"\\n\",\n",
    "     \"Precision:\",Dec_p.round(5),\"\\n\",\n",
    "     \"Recall:\", Dec_r.round(5), \"\\n\",\n",
    "     \"F-1 Score:\", Dec_f.round(5),\"\\n\",\n",
    "     \"Accuracy\",\"\\n\",\"\\t\"+\n",
    "     \"Test dataset:\", Dec_te.round(5),\"\\n\",\"\\t\"+\n",
    "     \"Train dataset:\",Dec_tr.round(5),\"\\n\",\"\\t\"+\n",
    "     \"Entire dataset:\", Dec_y.round(5),\"\\n\"*3,\n",
    "     \"\\t\",\"Random Forest\",\"\\n\",\n",
    "     \"Confusion Matrix:\",\"\\n\",Ran_c,\"\\n\",\n",
    "     \"Precision:\",Ran_p.round(5),\"\\n\",\n",
    "     \"Recall:\", Ran_r.round(5), \"\\n\",\n",
    "     \"F-1 Score:\", Ran_f.round(5),\"\\n\",\n",
    "     \"Accuracy\",\"\\n\",\"\\t\"+\n",
    "     \"Test dataset:\", Ran_te.round(5),\"\\n\",\"\\t\"+\n",
    "     \"Train dataset:\",Ran_tr.round(5),\"\\n\",\"\\t\"+\n",
    "     \"Entire dataset:\", Ran_y.round(5),\"\\n\"*3,\n",
    "     \"\\t\",\"AdaBoost\",\"\\n\",\n",
    "     \"Confusion Matrix:\",\"\\n\",Ada_c,\"\\n\",\n",
    "     \"Precision:\",Ada_p.round(5),\"\\n\",\n",
    "     \"Recall:\", Ada_r.round(5), \"\\n\",\n",
    "     \"F-1 Score:\", Ada_f.round(5),\"\\n\",\n",
    "     \"Accuracy\",\"\\n\",\"\\t\"+\n",
    "     \"Test dataset:\", Ada_te.round(5),\"\\n\",\"\\t\"+\n",
    "     \"Train dataset:\",Ada_tr.round(5),\"\\n\",\"\\t\"+\n",
    "     \"Entire dataset:\", Ada_y.round(5),\"\\n\"*3,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, explain the meaning of each number found in the confusion matrix from AdaBoost with respect to class labels. Do not simply label them as 'TP', 'FP', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of confusion matrix is: \n",
      "Top left is the amount of  + class predicted that were the same as the actual + class , \n",
      "Top right is the amount of - class predicted that were supposed to be actual + class \n",
      "Bottom left is the amount + class predicted that were supposed ot be - class predicted \n",
      "Botton right is the amount of - class predicted that were the same as the actual - class\n"
     ]
    }
   ],
   "source": [
    "print(\"The meaning of confusion matrix is:\",\"\\n\"\n",
    "      \"Top left is the amount of  + class predicted that were the same as the actual + class ,\", \"\\n\"+\n",
    "      \"Top right is the amount of - class predicted that were supposed to be actual + class\", \"\\n\"+\n",
    "     \"Bottom left is the amount + class predicted that were supposed ot be - class predicted\",\"\\n\"+\n",
    "     \"Botton right is the amount of - class predicted that were the same as the actual - class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "(1 point) Improve the accuracy of the AdaBoost better than 90% when it is trained on the same train set and evaluated on the entire set. You may configure AdaBoost differently from the default configuration. However, you may not make modification to the train and entire sets prepared in Problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the improved AdaBoost is: 90.289 percent\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate AdaBoost only\n",
    "# ADABOOST\n",
    "# 1 Train model\n",
    "Ada_Boo =  AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=5), # default estimator\n",
    "    n_estimators=200, # The maximum number of estimators\n",
    "    algorithm=\"SAMME.R\",\n",
    "    learning_rate=0.5, # shrinks the contribution of each classifier by learning_rate\n",
    "    random_state=42)\n",
    "Ada_Boo.fit(X_train,y_train)\n",
    "\n",
    "# 2 Prediction\n",
    "y_pred = Ada_Boo.predict(X_test)\n",
    "\n",
    "# 3 Now compute accuracy on the entire dataset. Has to be >90%\n",
    "y_pred = Ada_Boo.predict(X)\n",
    "Acc = accuracy_score(y,y_pred)\n",
    "\n",
    "\n",
    "print(\"The accuracy of the improved AdaBoost is:\", Acc.round(5)*100, \"percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 21.76927638053894 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "colab-tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
